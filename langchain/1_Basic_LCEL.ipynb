{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a99434d-c7b0-4c92-a674-a23b09b7a0ca",
   "metadata": {},
   "source": [
    "# Create a simple chatbot using LangChain and <br> NVIDIA AI Foundation Endpoints or NVIDIA NIM for LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8adbf6-0c61-434c-9bdc-bbaf7303b0bb",
   "metadata": {},
   "source": [
    "Please see [here](https://python.langchain.com/docs/integrations/text_embedding/nvidia_ai_endpoints) if you need help with generating the `NVIDIA_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6ef5dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "332bcd54-8341-48b6-bec5-4e81e24afd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "\n",
    "import os\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "# NVIDIA AI Foundation Endpoints\n",
    "llm = ChatNVIDIA(model=\"mistralai/mixtral-8x7b-instruct-v0.1\")\n",
    "\n",
    "# NVIDIA NIMs for LLMs\n",
    "# llm = ChatNVIDIA(base_url=\"http://localhost:8000/v1\", model=\"meta/llama3-8b-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18c1bde0-df19-41cb-988e-1ff11964d1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ChatNVIDIA model in LangChain Expression Language (LCEL)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", (\n",
    "        \"You are a helpful and friendly AI!\"\n",
    "        \"Your responses should be concise and no longer than two sentences.\"\n",
    "        \"Say you don't know if you don't have this information.\"\n",
    "    )),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f19b177c-aa8c-4fcd-af97-9bb1c5e3b8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A GPU, or Graphics Processing Unit, is a specialized type of processor designed to quickly render graphics, while a CPU, or Central Processing Unit, handles general computational tasks. They have different architectures and strengths, with GPUs excelling at parallel processing and CPUs at single-thread performance.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"question\": \"What's the difference between a GPU and a CPU?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01b92935-d8cc-478d-bf4d-377f40cdb827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, I don't have that specific information. The naming conventions of companies like NVIDIA often have internal logic, but they don't always make public the exact meaning of each letter or number in their product codes.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"question\": \"What does the A in the NVIDIA A100 stand for?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f7793e4-b332-46ca-bf0e-308faefd4745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, I don't have the specific information about the NVIDIA H200 graphics card's memory size. It would be best to check the official NVIDIA website or product specifications for the most accurate information.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"question\": \"How much memory does the NVIDIA H200 have?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58831966-85b0-4907-97c0-78e6aa447dd1",
   "metadata": {},
   "source": [
    "- The LLM can't provide an answer to the last question because it's limited by the information it was trained on. These models are only equipped with knowledge up to a certain point in time and don't have access to proprietary or recent data. As a result, they may struggle to address inquiries related to new or proprietary information.\n",
    "  \n",
    "- The following notebooks will demonstrate how we can use NeMo Retriever Embedding Microservice, NeMo Retriever Reranking Microservice, and NeMo Retriever to create a RAG workflow and provide new knowledge to the LLM."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
